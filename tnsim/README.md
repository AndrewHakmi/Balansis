# TNSIM - Theory of Zero-Sum Infinite Sets

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-13+-blue.svg)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

**TNSIM** (Theory of Zero-Sum Infinite Sets) is an innovative library for working with zero-sum sets and high-precision computations with rounding error compensation.

## ğŸš€ Key Features

- **High-precision computations**: Rounding error compensation algorithms
- **Zero-sum sets**: Working with infinite sets
- **Convergence analysis**: Tools for analyzing series convergence
- **Balansis integration**: Extended compensation capabilities
- **Zero-Sum Attention**: Attention mechanism for neural networks
- **REST API**: FastAPI interface for web integration
- **Parallel computing**: Multi-threaded processing
- **Caching**: Performance optimization

## ğŸ“¦ Installation

### Requirements

- Python 3.8+
- PostgreSQL 13+
- Docker (optional)

### Installation from source

```bash
git clone https://github.com/your-repo/tnsim.git
cd tnsim
pip install -r requirements.txt
```

### Installation with Docker

```bash
docker-compose up -d
```

## ğŸ—ï¸ Architecture

```
tnsim/
â”œâ”€â”€ core/                    # Core components
â”‚   â”œâ”€â”€ zero_sum_set.py     # ZeroSumInfiniteSet class
â”‚   â”œâ”€â”€ cache.py            # Caching system
â”‚   â””â”€â”€ parallel.py         # Parallel computing
â”œâ”€â”€ api/                     # FastAPI application
â”‚   â”œâ”€â”€ main.py             # Main application
â”‚   â”œâ”€â”€ routes/             # API routes
â”‚   â””â”€â”€ models/             # Pydantic models
â”œâ”€â”€ integrations/           # Integrations
â”‚   â””â”€â”€ balansis_integration.py
â”œâ”€â”€ database/               # Database
â”‚   â”œâ”€â”€ models.py           # SQLAlchemy models
â”‚   â””â”€â”€ connection.py       # Database connection
â”œâ”€â”€ tests/                  # Tests
â”œâ”€â”€ examples/               # Usage examples
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â””â”€â”€ docs/                   # Documentation
```

## ğŸ”§ Quick Start

### Basic usage

```python
from tnsim.core.zero_sum_set import ZeroSumInfiniteSet

# Create zero-sum set
elements = [1.0, -0.5, -0.3, -0.2]
zero_sum_set = ZeroSumInfiniteSet(elements)

# Validate
validation = zero_sum_set.validate_zero_sum()
print(f"Valid: {validation['is_valid']}")

# Compensated summation
result = zero_sum_set.zero_sum_operation(method='compensated')
print(f"Result: {result}")
```

### Convergence analysis

```python
# Create harmonic series
harmonic_elements = [1/i for i in range(1, 1001)]
harmonic_elements.append(-sum(harmonic_elements))

harmonic_set = ZeroSumInfiniteSet(harmonic_elements, series_type='harmonic')

# Convergence analysis
convergence = harmonic_set.convergence_analysis()
print(f"Converges: {convergence['converges']}")
print(f"Type: {convergence['convergence_type']}")
```

### Balansis integration

```python
from tnsim.integrations.balansis_integration import BalansisCompensator

# Create compensator
compensator = BalansisCompensator(precision='high')

# Compensate series
series = [0.1, 0.01, 0.001] * 100
result, metrics = compensator.compensate_series(series)

print(f"Result: {result}")
print(f"Quality: {metrics.quality_score}")
```

### Zero-Sum Attention

```python
from tnsim.integrations.balansis_integration import ZeroSumAttention
import numpy as np

# Create attention model
attention = ZeroSumAttention(
    d_model=64,
    n_heads=8,
    compensation_strength=0.1
)

# Forward pass
x = np.random.randn(4, 32, 64).astype(np.float32)
output, attention_weights = attention.forward(x)

print(f"Output: {output.shape}")
print(f"Attention weights: {attention_weights.shape}")
```

## ğŸŒ REST API

### Start server

```bash
cd tnsim/api
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Main endpoints

#### Create zero-sum set

```bash
curl -X POST "http://localhost:8000/api/zerosum/create" \
     -H "Content-Type: application/json" \
     -d '{
       "elements": [1.0, -0.5, -0.3, -0.2],
       "series_type": "custom"
     }'
```

#### Zero-sum operation

```bash
curl -X POST "http://localhost:8000/api/zerosum/operation" \
     -H "Content-Type: application/json" \
     -d '{
       "set_id": "uuid-here",
       "method": "compensated"
     }'
```

#### Convergence analysis

```bash
curl -X POST "http://localhost:8000/api/zerosum/convergence" \
     -H "Content-Type: application/json" \
     -d '{
       "set_id": "uuid-here"
     }'
```

## ğŸ—„ï¸ Database

### PostgreSQL setup

```sql
-- Create database
CREATE DATABASE tnsim_db;

-- Connect to database
\c tnsim_db;

-- Create tables (executed automatically on startup)
```

### Environment variables

```bash
# .env file
DATABASE_URL=postgresql://username:password@localhost:5432/tnsim_db
REDIS_URL=redis://localhost:6379/0
SECRET_KEY=your-secret-key
DEBUG=True
```

## ğŸ§ª Testing

### Run all tests

```bash
pytest tests/ -v
```

### Run specific tests

```bash
# Core component tests
pytest tests/test_zero_sum_set.py -v

# API tests
pytest tests/test_api.py -v

# Integration tests
pytest tests/test_balansis_integration.py -v
```

### Code coverage

```bash
pytest --cov=tnsim tests/
```

## ğŸ“Š Examples and Demonstrations

### Jupyter Notebooks

- `notebooks/zero_sum_theory_demo.ipynb` - Complete theory demonstration
- `notebooks/performance_analysis.ipynb` - Performance analysis
- `notebooks/financial_applications.ipynb` - Financial applications

### Code examples

- `examples/basic_usage.py` - Basic usage
- `examples/advanced_compensation.py` - Advanced compensation
- `examples/parallel_processing.py` - Parallel processing
- `examples/web_integration.py` - Web integration

## ğŸ”¬ Compensation Algorithms

### Available methods

1. **Direct** - Direct summation
2. **Compensated** - Kahan algorithm
3. **Iterative** - Iterative compensation
4. **Adaptive** - Adaptive compensation
5. **Stabilized** - Stabilized summation

### Performance comparison

| Method | Accuracy | Speed | Memory |
|--------|----------|-------|--------|
| Direct | â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| Compensated | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| Iterative | â­â­â­ | â­â­â­ | â­â­â­ |
| Adaptive | â­â­â­â­â­ | â­â­ | â­â­ |
| Stabilized | â­â­â­â­ | â­â­â­ | â­â­â­ |

## ğŸš€ Performance

### Benchmarks

```python
# Performance testing
from tnsim.benchmarks import run_performance_test

results = run_performance_test(
    sizes=[1000, 10000, 100000],
    methods=['direct', 'compensated', 'adaptive']
)

print(results.summary())
```

### Optimization

- Use caching for repetitive computations
- Apply parallel processing for large sets
- Choose appropriate compensation method for your task

## ğŸ”§ Configuration

### Cache settings

```python
from tnsim.core.cache import TNSIMCache

# Cache configuration
cache = TNSIMCache(
    max_size=1000,
    ttl=3600,  # 1 hour
    strategy='lru'
)
```

### Parallel processing

```python
from tnsim.core.parallel import ParallelTNSIM

# Parallel processing configuration
parallel_processor = ParallelTNSIM(
    num_workers=4,
    chunk_size=1000
)
```

## ğŸ¤ Contributing

### How to contribute

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Code standards

- Follow PEP 8
- Add docstrings for all functions
- Cover code with tests
- Update documentation

## ğŸ“š Documentation

### Complete documentation

- [API Reference](docs/api_reference.md)
- [Theoretical foundations](docs/theory.md)
- [Usage examples](docs/examples.md)
- [FAQ](docs/faq.md)

### Scientific papers

- "Theory of Zero-Sum Infinite Sets: Mathematical Foundations"
- "Compensation Algorithms for High-Precision Computing"
- "Zero-Sum Attention Mechanisms in Neural Networks"

## ğŸ› Known Issues

- Performance may degrade for very large sets (>10^6 elements)
- Some compensation methods require additional memory
- Integration with some NumPy versions may cause warnings

## ğŸ”® Roadmap

### Version 2.0

- [ ] Complex number support
- [ ] GPU acceleration with CUDA
- [ ] Quantum compensation algorithms
- [ ] Extended TensorFlow/PyTorch integration

### Version 2.1

- [ ] Automatic parameter optimization
- [ ] Web interface for visualization
- [ ] Distributed computing support
- [ ] Cloud platform integration

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Lead Developer** - [Your Name](https://github.com/yourusername)
- **Mathematical Consultant** - [Consultant Name](https://github.com/consultant)

## ğŸ™ Acknowledgments

- Balansis team for inspiration and support
- NumPy community for excellent tools
- All project contributors

## ğŸ“ Support

- **Email**: support@tnsim.org
- **Discord**: [TNSIM Community](https://discord.gg/tnsim)
- **Issues**: [GitHub Issues](https://github.com/your-repo/tnsim/issues)
- **Documentation**: [docs.tnsim.org](https://docs.tnsim.org)

---

**TNSIM** - Precision in every calculation! ğŸ¯